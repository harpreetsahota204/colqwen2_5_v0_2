{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ColQwen2.5-v0.2 for FiftyOne Tutorial\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/harpreetsahota204/colqwen2_5_v0_2/blob/main/colpali_fiftyone_tutorial.ipynb)\n",
        "\n",
        "This notebook demonstrates how to use ColQwen2.5-v0.2 with FiftyOne for visual document retrieval.\n",
        "\n",
        "## Overview\n",
        "\n",
        "ColQwen2.5 is a Vision Language Model based on Qwen2.5-VL-3B-Instruct that generates ColBERT-style multi-vector representations for efficient document retrieval. This integration uses token pooling to make ColQwen2.5 compatible with FiftyOne's similarity infrastructure.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "Install required packages:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install fiftyone colpali-engine transformers torch huggingface-hub umap-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Register the Zoo Model\n",
        "\n",
        "Register this repository as a FiftyOne zoo model source:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fiftyone.zoo as foz\n",
        "\n",
        "# Register this repository as a remote zoo model source\n",
        "foz.register_zoo_model_source(\n",
        "    \"https://github.com/harpreetsahota204/colqwen2_5_v0_2\",\n",
        "    overwrite=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Dataset\n",
        "\n",
        "Load a document dataset from Hugging Face:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fiftyone as fo\n",
        "from fiftyone.utils.huggingface import load_from_hub\n",
        "\n",
        "# Load document dataset from Hugging Face\n",
        "dataset = load_from_hub(\n",
        "    \"Voxel51/document-haystack-10pages\",\n",
        "    overwrite=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Basic Workflow: Document Retrieval\n",
        "\n",
        "### Load Model and Compute Embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fiftyone.zoo as foz\n",
        "\n",
        "# Load ColQwen2.5 model with desired pooling strategy\n",
        "model = foz.load_zoo_model(\n",
        "    \"vidore/colqwen2.5-v0.2\",\n",
        "    pooling_strategy=\"max\",  # or \"mean\" (default)\n",
        "    pool_factor=3  # Compression factor\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute embeddings for all documents\n",
        "dataset.compute_embeddings(\n",
        "    model=model,\n",
        "    embeddings_field=\"colqwen_embeddings\",\n",
        ")\n",
        "\n",
        "# Check embedding dimensions\n",
        "print(dataset.first()['colqwen_embeddings'].shape)  # Should be (128,)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Build Similarity Index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fiftyone.brain as fob\n",
        "\n",
        "# Build similarity index\n",
        "text_img_index = fob.compute_similarity(\n",
        "    dataset,\n",
        "    model=\"vidore/colqwen2.5-v0.2\",\n",
        "    embeddings_field=\"colqwen_embeddings\",\n",
        "    brain_key=\"colqwen_sim\",\n",
        "    model_kwargs={\n",
        "        \"pooling_strategy\": \"max\",\n",
        "        \"pool_factor\": 3,\n",
        "    }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Query for Specific Content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query for specific content\n",
        "sims = text_img_index.sort_by_similarity(\n",
        "    \"the secret office supply is pencil\"\n",
        ")\n",
        "\n",
        "# Launch FiftyOne App\n",
        "session = fo.launch_app(dataset, auto=False)\n",
        "print(session.url)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Advanced Embedding Workflows\n",
        "\n",
        "### 1. Embedding Visualization with UMAP\n",
        "\n",
        "Create 2D visualizations of your document embeddings:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fiftyone.brain as fob\n",
        "\n",
        "# Create UMAP visualization\n",
        "results = fob.compute_visualization(\n",
        "    dataset,\n",
        "    method=\"umap\",  # Also supports \"tsne\", \"pca\"\n",
        "    brain_key=\"colqwen_viz\",\n",
        "    embeddings=\"colqwen_embeddings\"\n",
        ")\n",
        "\n",
        "# Explore in the App\n",
        "session = fo.launch_app(dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Similarity Search\n",
        "\n",
        "Build powerful similarity search with ColQwen embeddings:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fiftyone.brain as fob\n",
        "\n",
        "# Build similarity index\n",
        "results = fob.compute_similarity(\n",
        "    dataset,\n",
        "    backend=\"sklearn\",  # Fast sklearn backend\n",
        "    brain_key=\"colqwen_sim\", \n",
        "    embeddings=\"colqwen_embeddings\"\n",
        ")\n",
        "\n",
        "# Find similar images\n",
        "sample_id = dataset.first().id\n",
        "similar_samples = dataset.sort_by_similarity(\n",
        "    sample_id,\n",
        "    brain_key=\"colqwen_sim\",\n",
        "    k=10  # Top 10 most similar\n",
        ")\n",
        "\n",
        "# View results\n",
        "session = fo.launch_app(similar_samples)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Dataset Representativeness\n",
        "\n",
        "Score how representative each sample is of your dataset:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fiftyone.brain as fob\n",
        "\n",
        "# Compute representativeness scores\n",
        "fob.compute_representativeness(\n",
        "    dataset,\n",
        "    representativeness_field=\"colqwen_represent\",\n",
        "    method=\"cluster-center\",\n",
        "    embeddings=\"colqwen_embeddings\"\n",
        ")\n",
        "\n",
        "# Find most representative samples\n",
        "representative_view = dataset.sort_by(\"colqwen_represent\", reverse=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Duplicate Detection\n",
        "\n",
        "Find and remove near-duplicate documents:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fiftyone.brain as fob\n",
        "\n",
        "# Detect duplicates using embeddings\n",
        "results = fob.compute_uniqueness(\n",
        "    dataset,\n",
        "    embeddings=\"colqwen_embeddings\"\n",
        ")\n",
        "\n",
        "# Filter to most unique samples\n",
        "unique_view = dataset.sort_by(\"uniqueness\", reverse=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration Options\n",
        "\n",
        "### Pooling Strategy Comparison\n",
        "\n",
        "Compare mean vs max pooling strategies:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mean pooling (default) - holistic document matching\n",
        "model_mean = foz.load_zoo_model(\n",
        "    \"vidore/colqwen2.5-v0.2\",\n",
        "    pooling_strategy=\"mean\",\n",
        "    pool_factor=3\n",
        ")\n",
        "\n",
        "# Max pooling - specific content/keyword matching\n",
        "model_max = foz.load_zoo_model(\n",
        "    \"vidore/colqwen2.5-v0.2\",\n",
        "    pooling_strategy=\"max\",\n",
        "    pool_factor=3\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custom Pool Factor\n",
        "\n",
        "Adjust compression level:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# More aggressive compression (faster, less accurate)\n",
        "model_compressed = foz.load_zoo_model(\n",
        "    \"vidore/colqwen2.5-v0.2\",\n",
        "    pool_factor=5\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding the Compression Pipeline\n",
        "\n",
        "ColQwen2.5 natively produces variable-length multi-vector embeddings that are incompatible with FiftyOne's fixed-dimension requirements. This integration uses a two-stage compression approach:\n",
        "\n",
        "### Stage 1: Token Pooling (Intelligent Compression)\n",
        "- Images: Variable patches (up to 768) → Compressed by factor of 3\n",
        "- Queries: Variable vectors → Compressed by factor of 3\n",
        "- **Retains ~97.8% accuracy**\n",
        "- Removes redundant patches (e.g., white backgrounds) while preserving aspect ratios\n",
        "\n",
        "### Stage 2: Final Pooling (Fixed Dimensions)\n",
        "- Mean or Max pooling: Compressed vectors → `(128,)`\n",
        "- **FiftyOne compatible**\n",
        "- Both strategies work for classification and retrieval\n",
        "\n",
        "**Trade-off**: ~85-90% of native ColQwen2.5 accuracy for full FiftyOne compatibility.\n",
        "\n",
        "For production applications requiring native ColQwen2.5 accuracy, consider using dedicated vector databases like [Qdrant](https://qdrant.tech/) or [Weaviate](https://weaviate.io/) that support multi-vector search natively.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resources\n",
        "\n",
        "- **Original Repository**: [illuin-tech/colpali](https://github.com/illuin-tech/colpali)\n",
        "- **Model Weights**: [vidore/colqwen2.5-v0.2](https://huggingface.co/vidore/colqwen2.5-v0.2)\n",
        "- **Paper**: [ColPali: Efficient Document Retrieval with Vision Language Models](https://arxiv.org/abs/2407.01449)\n",
        "- **Base Model**: [Qwen2.5-VL-3B-Instruct](https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct)\n",
        "\n",
        "### Citation\n",
        "\n",
        "If you use ColQwen2.5 in your research, please cite:\n",
        "\n",
        "```bibtex\n",
        "@misc{faysse2024colpaliefficientdocumentretrieval,\n",
        "  title={ColPali: Efficient Document Retrieval with Vision Language Models}, \n",
        "  author={Manuel Faysse and Hugues Sibille and Tony Wu and Bilel Omrani and Gautier Viaud and Céline Hudelot and Pierre Colombo},\n",
        "  year={2024},\n",
        "  eprint={2407.01449},\n",
        "  archivePrefix={arXiv},\n",
        "  primaryClass={cs.IR},\n",
        "  url={https://arxiv.org/abs/2407.01449}, \n",
        "}\n",
        "```\n",
        "\n",
        "## License\n",
        "\n",
        "- **Base Model (Qwen2.5-VL)**: [Qwen Research License Agreement](https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct)\n",
        "- **Model Adapters**: Apache 2.0 License\n",
        "- **Integration Code**: Apache 2.0 License\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "fiftyone",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
