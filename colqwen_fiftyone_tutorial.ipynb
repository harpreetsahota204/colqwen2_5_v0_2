{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ColQwen2.5-v0.2 for FiftyOne Tutorial\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/harpreetsahota204/colqwen2_5_v0_2/blob/main/colpali_fiftyone_tutorial.ipynb)\n",
        "\n",
        "This notebook demonstrates how to use ColQwen2.5-v0.2 with FiftyOne for visual document retrieval.\n",
        "\n",
        "## Overview\n",
        "\n",
        "ColQwen2.5 is a Vision Language Model based on Qwen2.5-VL-3B-Instruct that generates ColBERT-style multi-vector representations for efficient document retrieval. This integration uses token pooling to make ColQwen2.5 compatible with FiftyOne's similarity infrastructure.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup\n",
        "\n",
        "Install required packages:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install fiftyone colpali-engine transformers torch huggingface-hub umap-learn\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Register the Zoo Model\n",
        "\n",
        "Register this repository as a FiftyOne zoo model source:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/harpreetsahota204/ColQwen_v1_3...\n",
            "  150.5Kb [84.6ms elapsed, ? remaining, 1.7Mb/s] \n"
          ]
        }
      ],
      "source": [
        "import fiftyone.zoo as foz\n",
        "\n",
        "# Register this repository as a remote zoo model source\n",
        "foz.register_zoo_model_source(\n",
        "    \"https://github.com/harpreetsahota204/colqwen2_5_v0_2\",\n",
        "    overwrite=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Dataset\n",
        "\n",
        "Load a document dataset from Hugging Face:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading config file fiftyone.yml from Voxel51/document-haystack-10pages\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "28a32573ae0948458903d0de135929ab",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "fiftyone.yml:   0%|          | 0.00/104 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading dataset\n",
            "You are running the oldest supported major version of MongoDB. Please refer to https://deprecation.voxel51.com for deprecation notices. You can suppress this exception by setting your `database_validation` config parameter to `False`. See https://docs.voxel51.com/user_guide/config.html#configuring-a-mongodb-connection for more information\n",
            "Importing samples...\n",
            " 100% |█████████████████| 250/250 [9.6ms elapsed, 0s remaining, 26.0K samples/s]      \n",
            "Downloading 250 media files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 3/3 [01:06<00:00, 22.08s/it]\n"
          ]
        }
      ],
      "source": [
        "import fiftyone as fo\n",
        "from fiftyone.utils.huggingface import load_from_hub\n",
        "\n",
        "# Load document dataset from Hugging Face\n",
        "dataset = load_from_hub(\n",
        "    \"Voxel51/document-haystack-10pages\",\n",
        "    overwrite=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Basic Workflow: Document Retrieval\n",
        "\n",
        "### Load Model and Compute Embeddings\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "165905b2abd14ea980caf3384dc01875",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 10 files:   0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e550496f0b7f400dbfeb8400edbbcbfb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00001-of-00002.safetensors:   0%|          | 0.00/4.99G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f59640ad229a47ea9efe31828ab89def",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model-00002-of-00002.safetensors:   0%|          | 0.00/862M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "faf93f9712854284963e51e49a61080f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "preprocessor_config.json:   0%|          | 0.00/423 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "420bc1fd4ab44584aa64624040bfeb7a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "87e5b6d2dba0444ba692fea0f846d512",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/733 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a65f2edaed14b96b7c2bcaa95dba1c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors.index.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01fe9a6981b34a50b3d3f4e7e5e17eba",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              ".gitattributes: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b808dd3b21b041bf85f813d7316dc107",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "baafc6912ddb4468b9480c8e413ff7b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/34.6M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14ba4953b02d431782dc62dfe71d06e7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json: 0.00B [00:00, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "35795acd276a4069b9b969aa5ca1e9f8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import fiftyone.zoo as foz\n",
        "\n",
        "# Load ColQwen2.5 model with desired pooling strategy\n",
        "model = foz.load_zoo_model(\n",
        "    \"vidore/colqwen2.5-v0.2\",\n",
        "    pooling_strategy=\"max\",  # or \"mean\" (default)\n",
        "    pool_factor=3  # Compression factor\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "You are running the oldest supported major version of MongoDB. Please refer to https://deprecation.voxel51.com for deprecation notices. You can suppress this exception by setting your `database_validation` config parameter to `False`. See https://docs.voxel51.com/user_guide/config.html#configuring-a-mongodb-connection for more information\n",
            "You are running the oldest supported major version of MongoDB. Please refer to https://deprecation.voxel51.com for deprecation notices. You can suppress this exception by setting your `database_validation` config parameter to `False`. See https://docs.voxel51.com/user_guide/config.html#configuring-a-mongodb-connection for more information\n",
            "You are running the oldest supported major version of MongoDB. Please refer to https://deprecation.voxel51.com for deprecation notices. You can suppress this exception by setting your `database_validation` config parameter to `False`. See https://docs.voxel51.com/user_guide/config.html#configuring-a-mongodb-connection for more information\n",
            "You are running the oldest supported major version of MongoDB. Please refer to https://deprecation.voxel51.com for deprecation notices. You can suppress this exception by setting your `database_validation` config parameter to `False`. See https://docs.voxel51.com/user_guide/config.html#configuring-a-mongodb-connection for more information\n",
            "You are running the oldest supported major version of MongoDB. Please refer to https://deprecation.voxel51.com for deprecation notices. You can suppress this exception by setting your `database_validation` config parameter to `False`. See https://docs.voxel51.com/user_guide/config.html#configuring-a-mongodb-connection for more information\n",
            "You are running the oldest supported major version of MongoDB. Please refer to https://deprecation.voxel51.com for deprecation notices. You can suppress this exception by setting your `database_validation` config parameter to `False`. See https://docs.voxel51.com/user_guide/config.html#configuring-a-mongodb-connection for more information\n",
            "You are running the oldest supported major version of MongoDB. Please refer to https://deprecation.voxel51.com for deprecation notices. You can suppress this exception by setting your `database_validation` config parameter to `False`. See https://docs.voxel51.com/user_guide/config.html#configuring-a-mongodb-connection for more information\n",
            "You are running the oldest supported major version of MongoDB. Please refer to https://deprecation.voxel51.com for deprecation notices. You can suppress this exception by setting your `database_validation` config parameter to `False`. See https://docs.voxel51.com/user_guide/config.html#configuring-a-mongodb-connection for more information\n",
            "  21% |███\\-------------|  52/250 [3.4m elapsed, 13.2m remaining, 0.2 samples/s]  "
          ]
        }
      ],
      "source": [
        "# Compute embeddings for all documents\n",
        "dataset.compute_embeddings(\n",
        "    model=model,\n",
        "    embeddings_field=\"colqwen_embeddings\",\n",
        ")\n",
        "\n",
        "# Check embedding dimensions\n",
        "print(dataset.first()['colqwen_embeddings'].shape)  # Should be (128,)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Build Similarity Index\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fiftyone.brain as fob\n",
        "\n",
        "# Build similarity index\n",
        "text_img_index = fob.compute_similarity(\n",
        "    dataset,\n",
        "    model=\"vidore/colqwen2.5-v0.2\",\n",
        "    embeddings_field=\"colqwen_embeddings\",\n",
        "    brain_key=\"colqwen_sim\",\n",
        "    model_kwargs={\n",
        "        \"pooling_strategy\": \"max\",\n",
        "        \"pool_factor\": 3,\n",
        "    }\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Query for Specific Content\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Query for specific content\n",
        "sims = text_img_index.sort_by_similarity(\n",
        "    \"the secret office supply is pencil\"\n",
        ")\n",
        "\n",
        "# Launch FiftyOne App\n",
        "session = fo.launch_app(dataset, auto=False)\n",
        "print(session.url)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Advanced Embedding Workflows\n",
        "\n",
        "### 1. Embedding Visualization with UMAP\n",
        "\n",
        "Create 2D visualizations of your document embeddings:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fiftyone.brain as fob\n",
        "\n",
        "# Create UMAP visualization\n",
        "results = fob.compute_visualization(\n",
        "    dataset,\n",
        "    method=\"umap\",  # Also supports \"tsne\", \"pca\"\n",
        "    brain_key=\"colqwen_viz\",\n",
        "    embeddings=\"colqwen_embeddings\"\n",
        ")\n",
        "\n",
        "# Explore in the App\n",
        "session = fo.launch_app(dataset)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Similarity Search\n",
        "\n",
        "Build powerful similarity search with ColQwen embeddings:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fiftyone.brain as fob\n",
        "\n",
        "# Build similarity index\n",
        "results = fob.compute_similarity(\n",
        "    dataset,\n",
        "    backend=\"sklearn\",  # Fast sklearn backend\n",
        "    brain_key=\"colqwen_sim\", \n",
        "    embeddings=\"colqwen_embeddings\"\n",
        ")\n",
        "\n",
        "# Find similar images\n",
        "sample_id = dataset.first().id\n",
        "similar_samples = dataset.sort_by_similarity(\n",
        "    sample_id,\n",
        "    brain_key=\"colqwen_sim\",\n",
        "    k=10  # Top 10 most similar\n",
        ")\n",
        "\n",
        "# View results\n",
        "session = fo.launch_app(similar_samples)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Dataset Representativeness\n",
        "\n",
        "Score how representative each sample is of your dataset:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fiftyone.brain as fob\n",
        "\n",
        "# Compute representativeness scores\n",
        "fob.compute_representativeness(\n",
        "    dataset,\n",
        "    representativeness_field=\"colqwen_represent\",\n",
        "    method=\"cluster-center\",\n",
        "    embeddings=\"colqwen_embeddings\"\n",
        ")\n",
        "\n",
        "# Find most representative samples\n",
        "representative_view = dataset.sort_by(\"colqwen_represent\", reverse=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Duplicate Detection\n",
        "\n",
        "Find and remove near-duplicate documents:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import fiftyone.brain as fob\n",
        "\n",
        "# Detect duplicates using embeddings\n",
        "results = fob.compute_uniqueness(\n",
        "    dataset,\n",
        "    embeddings=\"colqwen_embeddings\"\n",
        ")\n",
        "\n",
        "# Filter to most unique samples\n",
        "unique_view = dataset.sort_by(\"uniqueness\", reverse=True)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration Options\n",
        "\n",
        "### Pooling Strategy Comparison\n",
        "\n",
        "Compare mean vs max pooling strategies:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Mean pooling (default) - holistic document matching\n",
        "model_mean = foz.load_zoo_model(\n",
        "    \"vidore/colqwen2.5-v0.2\",\n",
        "    pooling_strategy=\"mean\",\n",
        "    pool_factor=3\n",
        ")\n",
        "\n",
        "# Max pooling - specific content/keyword matching\n",
        "model_max = foz.load_zoo_model(\n",
        "    \"vidore/colqwen2.5-v0.2\",\n",
        "    pooling_strategy=\"max\",\n",
        "    pool_factor=3\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Custom Pool Factor\n",
        "\n",
        "Adjust compression level:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# More aggressive compression (faster, less accurate)\n",
        "model_compressed = foz.load_zoo_model(\n",
        "    \"vidore/colqwen2.5-v0.2\",\n",
        "    pool_factor=5\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Understanding the Compression Pipeline\n",
        "\n",
        "ColQwen2.5 natively produces variable-length multi-vector embeddings that are incompatible with FiftyOne's fixed-dimension requirements. This integration uses a two-stage compression approach:\n",
        "\n",
        "### Stage 1: Token Pooling (Intelligent Compression)\n",
        "- Images: Variable patches (up to 768) → Compressed by factor of 3\n",
        "- Queries: Variable vectors → Compressed by factor of 3\n",
        "- **Retains ~97.8% accuracy**\n",
        "- Removes redundant patches (e.g., white backgrounds) while preserving aspect ratios\n",
        "\n",
        "### Stage 2: Final Pooling (Fixed Dimensions)\n",
        "- Mean or Max pooling: Compressed vectors → `(128,)`\n",
        "- **FiftyOne compatible**\n",
        "- Both strategies work for classification and retrieval\n",
        "\n",
        "**Trade-off**: ~85-90% of native ColQwen2.5 accuracy for full FiftyOne compatibility.\n",
        "\n",
        "For production applications requiring native ColQwen2.5 accuracy, consider using dedicated vector databases like [Qdrant](https://qdrant.tech/) or [Weaviate](https://weaviate.io/) that support multi-vector search natively.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Resources\n",
        "\n",
        "- **Original Repository**: [illuin-tech/colpali](https://github.com/illuin-tech/colpali)\n",
        "- **Model Weights**: [vidore/colqwen2.5-v0.2](https://huggingface.co/vidore/colqwen2.5-v0.2)\n",
        "- **Paper**: [ColPali: Efficient Document Retrieval with Vision Language Models](https://arxiv.org/abs/2407.01449)\n",
        "- **Base Model**: [Qwen2.5-VL-3B-Instruct](https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct)\n",
        "\n",
        "### Citation\n",
        "\n",
        "If you use ColQwen2.5 in your research, please cite:\n",
        "\n",
        "```bibtex\n",
        "@misc{faysse2024colpaliefficientdocumentretrieval,\n",
        "  title={ColPali: Efficient Document Retrieval with Vision Language Models}, \n",
        "  author={Manuel Faysse and Hugues Sibille and Tony Wu and Bilel Omrani and Gautier Viaud and Céline Hudelot and Pierre Colombo},\n",
        "  year={2024},\n",
        "  eprint={2407.01449},\n",
        "  archivePrefix={arXiv},\n",
        "  primaryClass={cs.IR},\n",
        "  url={https://arxiv.org/abs/2407.01449}, \n",
        "}\n",
        "```\n",
        "\n",
        "## License\n",
        "\n",
        "- **Base Model (Qwen2.5-VL)**: [Qwen Research License Agreement](https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct)\n",
        "- **Model Adapters**: Apache 2.0 License\n",
        "- **Integration Code**: Apache 2.0 License\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "fiftyone",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
